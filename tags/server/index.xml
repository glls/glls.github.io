<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Server | George Litos</title>
    <link>https://georgelitos.com/tags/server/</link>
      <atom:link href="https://georgelitos.com/tags/server/index.xml" rel="self" type="application/rss+xml" />
    <description>Server</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Sun, 10 Sep 2023 18:00:00 +0300</lastBuildDate>
    <image>
      <url>https://georgelitos.com/media/icon_hu2521745571622303128.png</url>
      <title>Server</title>
      <link>https://georgelitos.com/tags/server/</link>
    </image>
    
    <item>
      <title>The correct way to benchmark your web server</title>
      <link>https://georgelitos.com/post/benchmark-webserver/</link>
      <pubDate>Sun, 10 Sep 2023 18:00:00 +0300</pubDate>
      <guid>https://georgelitos.com/post/benchmark-webserver/</guid>
      <description>&lt;p&gt;Keeping your web server running smoothly is crucial for a positive user experience. But how do you know it can handle the traffic you expect? Benchmarking is the answer! It allows you to simulate real-world load and measure your server&amp;rsquo;s performance. This post will guide you through using &lt;code&gt;wrk&lt;/code&gt;, a powerful tool for benchmarking your web server.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;wrk&lt;/code&gt; is a fast, user-friendly HTTP benchmarking tool. It&amp;rsquo;s lightweight and easy to install. Once you have wrk set up, you can start crafting your benchmark test. &lt;code&gt;wrk&lt;/code&gt; offers various options to configure your test precisely. You can define the number of threads to simulate concurrent users, the number of connections per thread, and the test duration. &lt;code&gt;wrk&lt;/code&gt; also allows you to specify headers to be sent with each request, mimicking real user behavior.&lt;/p&gt;
&lt;p&gt;Running a &lt;code&gt;wrk&lt;/code&gt; test is straightforward. You provide the URL you want to benchmark along with the desired configuration options. Wrks then bombards your server with simulated traffic, measuring critical metrics like request latency, throughput, and overall system health. After the test concludes, &lt;code&gt;wrk&lt;/code&gt; presents a detailed report. This report showcases valuable data points like average request time, request rate, and connection errors. Analyzing this data helps you identify bottlenecks and areas for improvement in your web server&amp;rsquo;s performance.&lt;/p&gt;
&lt;p&gt;By incorporating &lt;code&gt;wrk&lt;/code&gt; into your routine, you gain valuable insights into your web server&amp;rsquo;s capabilities. This allows you to optimize your server&amp;rsquo;s configuration, ensuring it can handle peak traffic and deliver a seamless user experience.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s an excerpt from the &lt;code&gt;wrk&lt;/code&gt; project&amp;rsquo;s &lt;a href=&#34;https://github.com/wg/wrk&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;README on GitHub&lt;/a&gt; for quick reference:&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;basic-usage&#34;&gt;Basic Usage&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wrk -t12 -c400 -d30s http://127.0.0.1:8080/index.html
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This runs a benchmark for 30 seconds, using 12 threads, and keeping
400 HTTP connections open.&lt;/p&gt;
&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Running 30s test @ http://127.0.0.1:8080/index.html
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  12 threads and 400 connections
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  Thread Stats   Avg      Stdev     Max   +/- Stdev
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Latency   635.91us    0.89ms  12.92ms   93.69%
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Req/Sec    56.20k     8.07k   62.00k    86.54%
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  22464657 requests in 30.00s, 17.76GB read
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Requests/sec: 748868.53
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Transfer/sec:    606.33MB
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;command-line-options&#34;&gt;Command Line Options&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    -c, --connections: total number of HTTP connections to keep open with
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                       each thread handling N = connections/threads
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    -d, --duration:    duration of the test, e.g. 2s, 2m, 2h
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    -t, --threads:     total number of threads to use
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    -s, --script:      LuaJIT script, see SCRIPTING
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    -H, --header:      HTTP header to add to request, e.g. &amp;#34;User-Agent: wrk&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        --latency:     print detailed latency statistics
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        --timeout:     record a timeout if a response is not received within
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                       this amount of time.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;benchmarking-tips&#34;&gt;Benchmarking Tips&lt;/h2&gt;
&lt;p&gt;The machine running wrk must have a sufficient number of ephemeral ports available and closed sockets should be recycled quickly. To handle the initial connection burst the server&amp;rsquo;s listen backlog should be greater than the number of concurrent connections being tested.&lt;/p&gt;
&lt;p&gt;A user script that only changes the HTTP method, path, adds headers or
a body, will have no performance impact. Per-request actions, particularly
building a new HTTP request, and use of response() will necessarily reduce
the amount of load that can be generated.&lt;/p&gt;
&lt;h2 id=&#34;showtime-&#34;&gt;Showtime ðŸš€&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Write a program that can serve a list of 100 albums with a REST like interface (JSON) and measure the performance with wrk&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Here&amp;rsquo;s the project in GitHub with full source code and implementations in more than 8 languages: &lt;a href=&#34;https://github.com/glls/web-service-albums-benchmark&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;web-service-albums-benchmark&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And the results:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://github.com/glls/web-service-albums-benchmark/raw/main/chart.svg&#34; alt=&#34;Chart&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s clear that Rust and Go are the speed demons when it comes to this particular task. However, threading and concurrency can be a game-changer in terms of performance. The key takeaway is that your server&amp;rsquo;s capabilities play a significant role in determining the optimal approach. For instance, if you&amp;rsquo;re running on a 4-core CPU, don&amp;rsquo;t expect more than 4 threads to run simultaneously - it&amp;rsquo;s like trying to fit too many eggs in one basket! So, before making any changes to your tech stack, take some time to consider these factors and plan accordingly.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
