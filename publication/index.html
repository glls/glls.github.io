<!DOCTYPE html>
<!-- This site was created with Wowchemy. https://www.wowchemy.com -->
<!-- Last Published: May 24, 2023 --><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.7.0 for Hugo" />
  

  
  












  
  










  







  
  

  
  
  

  
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css" media="print" onload="this.media='all'">

  
  
  
    
    

    
    
    
    
      
      
    
    
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.437a5ee446050af6395ec26f2f8fb847.css" />

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  






<script async src="https://www.googletagmanager.com/gtag/js?id=UA-89694050-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'UA-89694050-1', { 'anonymize_ip': true });
  gtag('set', {'cookie_flags': 'SameSite=None;Secure'});

  
  document.addEventListener('click', onClickCallback, false);
</script>























  
  
  






  <meta name="author" content="George Litos" />





  

<meta name="description" content="George Litos&#39;s personal website" />



<link rel="alternate" hreflang="en-us" href="https://georgelitos.com/publication/" />
<link rel="canonical" href="https://georgelitos.com/publication/" />



  <link rel="manifest" href="/manifest.webmanifest" />



<link rel="icon" type="image/png" href="/media/icon_hudd78b5bc2e9f708bbbb3651dc62e55b2_16066_32x32_fill_mitchellnetravali_center_3.png" />
<link rel="apple-touch-icon" type="image/png" href="/media/icon_hudd78b5bc2e9f708bbbb3651dc62e55b2_16066_180x180_fill_mitchellnetravali_center_3.png" />

<meta name="theme-color" content="#158cba" />










  
  






<meta property="twitter:card" content="summary" />

  <meta property="twitter:site" content="@gl_ls" />
  <meta property="twitter:creator" content="@gl_ls" />
<meta property="twitter:image" content="https://georgelitos.com/media/icon_hudd78b5bc2e9f708bbbb3651dc62e55b2_16066_512x512_fill_mitchellnetravali_center_3.png" />
<meta property="og:site_name" content="George Litos" />
<meta property="og:url" content="https://georgelitos.com/publication/" />
<meta property="og:title" content="Publications | George Litos" />
<meta property="og:description" content="George Litos&#39;s personal website" /><meta property="og:image" content="https://georgelitos.com/media/icon_hudd78b5bc2e9f708bbbb3651dc62e55b2_16066_512x512_fill_mitchellnetravali_center_3.png" /><meta property="og:locale" content="en-us" />

  
    <meta property="og:updated_time" content="2017-07-01T00:00:00&#43;00:00" />
  










  
  
  

  
  
    <link rel="alternate" href="/publication/index.xml" type="application/rss+xml" title="George Litos" />
  

  
  
  
  
  
    <script src="https://cdn.jsdelivr.net/gh/osano/cookieconsent@3.1.1/build/cookieconsent.min.js" integrity="sha512-yXXqOFjdjHNH1GND+1EO0jbvvebABpzGKD66djnUfiKlYME5HGMUJHoCaeE4D5PTG2YsSJf6dwqyUUvQvS0vaA==" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/osano/cookieconsent@3.1.1/build/cookieconsent.min.css" integrity="sha512-LQ97camar/lOliT/MqjcQs5kWgy6Qz/cCRzzRzUCfv0fotsCTC9ZHXaPQmJV8Xu/PVALfJZ7BDezl5lW3/qBxg==" crossorigin="anonymous">
  
  <script>
  window.addEventListener("load", function(){
    window.cookieconsent.initialise({
      "palette": {
        "popup": {
          "background": "#158cba",
          "text": "rgb(255, 255, 255)"
        },
        "button": {
          "background": "rgb(255, 255, 255)",
          "text": "#158cba"
        }
      },
      "theme": "classic",
      "content": {
        "message": "This website uses cookies to ensure you get the best experience on our website.",
        "dismiss": "Got it!",
        "link": "Learn more",
        "href": "https://www.cookiesandyou.com"
      }
    })});
  </script>



  
  <title>Publications | George Litos</title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="3a079e7dad19be978a318345a7749d34" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.535952bb111a9cecb5cfb11e29291991.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header header--fixed">
    












<header>
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">George Litos</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">George Litos</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#posts"><span>Posts</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#projects"><span>Projects</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#publications"><span>Publications</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    
















  

  
  
  
    
  
<div class="universal-wrapper pt-3">
  <h1>Publications</h1>

  

  
</div>



<div class="universal-wrapper">
  <div class="row">
    <div class="col-lg-12">

      

      
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      

      <div class="form-row mb-4">
        <div class="col-auto">
          <input type="search" class="filter-search form-control form-control-sm" placeholder="Search..." autocapitalize="off"
          autocomplete="off" autocorrect="off" role="textbox" spellcheck="false">
        </div>
        <div class="col-auto">
          <select class="pub-filters pubtype-select form-control form-control-sm" data-filter-group="pubtype">
            <option value="*">Type</option>
            
            
            <option value=".pubtype-1">
              Conference paper
            </option>
            
            <option value=".pubtype-2">
              Journal article
            </option>
            
            <option value=".pubtype-6">
              Book section
            </option>
            
          </select>
        </div>
        <div class="col-auto">
          <select class="pub-filters form-control form-control-sm" data-filter-group="year">
            <option value="*">Date</option>
            
            
            
            <option value=".year-2017">
              2017
            </option>
            
            <option value=".year-2012">
              2012
            </option>
            
            <option value=".year-2011">
              2011
            </option>
            
            <option value=".year-2006">
              2006
            </option>
            
            <option value=".year-2005">
              2005
            </option>
            
            
          </select>
        </div>
      </div>

      <div id="container-publications">
        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2017">
          











  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      M.L.Durova</span>, <span >
      A.Dimou</span>, <span class="author-highlighted">
      George Litos</span>, <span >
      P.Daras</span>, <span >
      J.P.Davis</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    July, 2017
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      In ICDP 2017: 8th IET International Conference of Imaging for Crime Detection and Prevention
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    <a href="/publication/toomanyeyes/" >
      <div class="img-hover-zoom">
        <img src="/publication/toomanyeyes/featured_hu1574738e0f3d2c0efe7a8452c938c5c5_68321_808x455_fill_q80_h2_mitchellnetravali_smart1_3.webp" height="455" width="808"
            class="article-banner" alt="TooManyEyes: Super-recogniser directed identification of target individuals on CCTV" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/toomanyeyes/" >TooManyEyes: Super-recogniser directed identification of target individuals on CCTV</a>
  </div>

  
  <a href="/publication/toomanyeyes/"  class="summary-link">
    <div class="article-style">
      <p>For the current research, a ‘Spot the Face in a Crowd Test’ (SFCT) comprising six video clips depicting target-actors and multiple bystanders was loaded on TooManyEyes, a bespoke multi-media platform adapted here for the human-directed identification of individuals in CCTV footage. To test the utility of TooManyEyes, police ‘super-recognisers’ (SRs) who may possess exceptional face recognition ability, and police controls attempted to identify the target-actors from the SFCT. As expected, SRs correctly identified more target-actors; with higher confidence than controls. As such, the TooManyEyes system provides a useful platform for uploading tests for selecting police or security staff for CCTV review deployment.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="http://www.iti.gr/iti/files/document/work/Durova%20et%20al%202017%20-%20PUBLISHED%20VERSION.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/toomanyeyes/cite.bib">
  Cite
</a>





<a class="btn btn-outline-primary btn-page-header btn-sm" href="http://www.lasie-project.eu/" target="_blank" rel="noopener">
  Project
</a>









<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1049/ic.2017.0047" target="_blank" rel="noopener">
  DOI
</a>



  </div>
  

</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2012">
          











  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      H.Dutagaci</span>, <span >
      A.Godil</span>, <span >
      P.Daras</span>, <span >
      A.Axenopoulos</span>, <span class="author-highlighted">
      George Litos</span>, <span >
      S.Manolopoulou</span>, <span >
      K.Goto</span>, <span >
      T.Yanagimachi</span>, <span >
      Y.Kurita</span>, <span >
      S.Kawamura</span>, <span >
      T.Furuya</span>, <span >
      R.Ohbuchi</span>, <span >
      B.Gong</span>, <span >
      J.Liu</span>, <span >
      X.Tang</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    April, 2012
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      3DOR 2011
    
  </span>
  

  

  
  
  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/category/computer-vision/">Computer Vision</a></span>
  

</div>

  

  
  
  
    
    <a href="/publication/shrec/" >
      <div class="img-hover-zoom">
        <img src="/publication/shrec/featured_hudb2f00eb748596bbbb4c7d85f205b0b7_631934_808x455_fill_q80_h2_mitchellnetravali_smart1_3.webp" height="455" width="808"
            class="article-banner" alt="SHREC’11 Track: Generic Shape Retrieval" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/shrec/" >SHREC’11 Track: Generic Shape Retrieval</a>
  </div>

  
  <a href="/publication/shrec/"  class="summary-link">
    <div class="article-style">
      <p>In this paper we present the results of the 3D Shape Retrieval Contest 2011 (SHREC'11) track on generic shape retrieval. The aim of this track is to evaluate the performance of 3D shape retrieval algorithms that can operate on arbitrary 3D models. The benchmark dataset consists of 1000 3D objects classified in 50 categories. The 3D models are mainly classified based on visual shape similarity and each class has equal number of models to reduce the possible bias in evaluation results. Two groups have participated in the track with six methods in total.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="http://arxiv.org/pdf/1512.04133v1" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/shrec/cite.bib">
  Cite
</a>



  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.nist.gov/itl/iad/shrec-2011-datasets" target="_blank" rel="noopener">
  Dataset
</a>











<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.2312/3DOR/3DOR11/065-069" target="_blank" rel="noopener">
  DOI
</a>


  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.nist.gov/itl/iad/shrec-2011-shape-retrieval-contest-non-rigid-3d-watertight-meshes" target="_blank" rel="noopener">
    SHREC 2011</a>


  </div>
  

</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2012">
          











  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      P.Daras</span>, <span >
      A.Axenopoulos</span>, <span class="author-highlighted">
      George Litos</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    April, 2012
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      IEEE Transactions on Multimedia, Vol. 14, No. 2, Page(s): 374 – 388, April 2012
    
  </span>
  

  

  
  
  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/category/computer-vision/">Computer Vision</a></span>
  

</div>

  

  
  
  
    
    <a href="/publication/3d-object-retrieval/" >
      <div class="img-hover-zoom">
        <img src="/publication/3d-object-retrieval/featured_huc02043fe245efc3706adc836a44f7107_276083_808x455_fill_q80_h2_mitchellnetravali_smart1_3.webp" height="455" width="808"
            class="article-banner" alt="Investigating the Effects of Multiple Factors towards more Accurate 3D Object Retrieval" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/3d-object-retrieval/" >Investigating the Effects of Multiple Factors towards more Accurate 3D Object Retrieval</a>
  </div>

  
  <a href="/publication/3d-object-retrieval/"  class="summary-link">
    <div class="article-style">
      <p>This paper proposes a novel framework for 3-D object retrieval, taking into account most of the factors that may affect the retrieval performance. Initially, a novel 3-D model alignment method is introduced, which achieves accurate rotation estimation through the combination of two intuitive criteria, plane reflection symmetry and rectilinearity. After the pose normalization stage, a low-level descriptor extraction procedure follows, using three different types of descriptors, which have been proven to be effective. Then, a novel combination procedure of the above descriptors takes place, which achieves higher retrieval performance than each descriptor does separately. The paper provides also an in-depth study of the factors that can further improve the 3-D object retrieval accuracy. These include selection of the appropriate dissimilarity metric, feature selection/dimensionality reduction on the initial low-level descriptors, as well as manifold learning for re-ranking of the search results. Experiments performed on two 3-D model benchmark datasets confirm our assumption that future research in 3-D object retrieval should focus more on the efficient combination of low-level descriptors as well as on the selection of the best features and matching metrics, than on the investigation of the optimal 3-D object descriptor.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="http://www.iti.gr/iti/files/document/publications/IEEE%20MM0412.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/3d-object-retrieval/cite.bib">
  Cite
</a>













<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/TMM.2011.2176111" target="_blank" rel="noopener">
  DOI
</a>



  </div>
  

</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-6 year-2011">
          











  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      Stamatia Dasiopoulou</span>, <span >
      Eirini Giannakidou</span>, <span class="author-highlighted">
      George Litos</span>, <span >
      Polyxeni Malasioti</span>, <span >
      Yiannis Kompatsiaris</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    May, 2011
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      Knowledge-Driven Multimedia Information Extraction and Ontology Evolution pp 196-239
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    <a href="/publication/semantic-survey/" >
      <div class="img-hover-zoom">
        <img src="/publication/semantic-survey/featured_huddf1108a8232cc6f821cb43513930c41_21265_808x455_fill_q80_h2_mitchellnetravali_smart1.webp" height="455" width="808"
            class="article-banner" alt="A Survey of Semantic Image and Video Annotation Tools" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/semantic-survey/" >A Survey of Semantic Image and Video Annotation Tools</a>
  </div>

  
  <a href="/publication/semantic-survey/"  class="summary-link">
    <div class="article-style">
      <p>The availability of semantically annotated image and video assets constitutes a critical prerequisite for the realisation of intelligent knowledge management services pertaining to realistic user needs. Given the extend of the challenges involved in the automatic extraction of such descriptions, manually created metadata play a significant role, further strengthened by their deployment in training and evaluation tasks related to the automatic extraction of content descriptions. The different views taken by the two main approaches towards semantic content description, namely the Semantic Web and MPEG-7, as well as the traits particular to multimedia content due to the multiplicity of information levels involved, have resulted in a variety of image and video annotation tools, adopting varying description aspects. Aiming to provide a common framework of reference and furthermore to highlight open issues, especially with respect to the coverage and the interoperability of the produced metadata, in this chapter we present an overview of the state of the art in image and video annotation tools.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.researchgate.net/publication/220915805_A_Survey_of_Semantic_Image_and_Video_Annotation_Tools/download" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/semantic-survey/cite.bib">
  Cite
</a>













<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1007/978-3-642-20795-2_8" target="_blank" rel="noopener">
  DOI
</a>


  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://link.springer.com/book/10.1007/978-3-642-20795-2" target="_blank" rel="noopener">
    Book</a>


  </div>
  

</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2011">
          











  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      A.Axenopoulos</span>, <span class="author-highlighted">
      George Litos</span>, <span >
      P.Daras</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    April, 2011
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      1st ACM International Conference on Multimedia Retrieval (ICMR2011), April 17-20, Trento, Italy
    
  </span>
  

  

  
  
  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/category/3d-stereo-scene-analysis/">3D Stereo Scene Analysis</a>, <a href="/category/computer-vision/">Computer Vision</a></span>
  

</div>

  

  
  
  
    
    <a href="/publication/3d-model-retrieval/" >
      <div class="img-hover-zoom">
        <img src="/publication/3d-model-retrieval/featured_hu7676d622124c850a57ef2d84778c5b33_324115_808x455_fill_q80_h2_mitchellnetravali_smart1_3.webp" height="455" width="808"
            class="article-banner" alt="3D Model Retrieval using Accurate Pose Estimation and View-based Similarity" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/3d-model-retrieval/" >3D Model Retrieval using Accurate Pose Estimation and View-based Similarity</a>
  </div>

  
  <a href="/publication/3d-model-retrieval/"  class="summary-link">
    <div class="article-style">
      <p>In this paper, a novel framework for 3D object retrieval is presented. The paper focuses on the investigation of an accurate D model alignment method, which is achieved by combining two intuitive criteria, the plane reflection symmetry and rectilinearity. After proper positioning in a coordinate system, a set of 2D images (multi-views) are automatically generated from the 3D object, by taking views from uniformly distributed viewpoints. For each image, a set of flip-invariant shape descriptors is extracted. Taking advantage of both the pose estimation of the 3D objects and the flip-invariance property of the extracted descriptors, a new matching scheme for fast computation of 3D object dissimilarity is introduced. Experiments conducted in SHREC 2009 benchmark show the superiority of the pose estimation method over similar approaches, as well as the efficiency of the new matching scheme.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.researchgate.net/profile/Petros_Daras/publication/221318549_3D_model_retrieval_using_accurate_pose_estimation_and_view-based_similarity/links/0c96052b3ff587ac22000000/3D-model-retrieval-using-accurate-pose-estimation-and-view-based-similarity.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/3d-model-retrieval/cite.bib">
  Cite
</a>













<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1145/1991996.1992037" target="_blank" rel="noopener">
  DOI
</a>



  </div>
  

</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-1 year-2006">
          











  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">
      George Litos</span>, <span >
      X.Zabulis</span>, <span >
      G.A.Triantafyllidis</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    June, 2006
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      2006 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW'06)
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    <a href="/publication/network-synchronization/" >
      <div class="img-hover-zoom">
        <img src="/publication/network-synchronization/featured_hu788e8d71f84a7d470b92bf9f05717d5e_25306_808x455_fill_q80_h2_mitchellnetravali_smart1_3.webp" height="455" width="808"
            class="article-banner" alt="Synchronous Image Acquisition based on Network Synchronization" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/network-synchronization/" >Synchronous Image Acquisition based on Network Synchronization</a>
  </div>

  
  <a href="/publication/network-synchronization/"  class="summary-link">
    <div class="article-style">
      <p>In this paper, a software-based system for the real-time synchronization of images captured by a low-cost camera framework is presented. It is most well suited for cases where special hardware cannot be utilized (e.g. remote or wireless applications) and when cost efficiency is critical. The proposed method utilizes messages to establish a consensus on the time of image acquisition and NTP synchronization of computer clocks. It also provides with an error signal, in case of failure of the synchronization. The evaluation of the proposed algorithm using a precise LED array system (1ms accuracy) proves the effectiveness of this method.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.researchgate.net/publication/232617620_Synchronous_Image_Acquisition_based_on_Network_Synchronization/download" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/network-synchronization/cite.bib">
  Cite
</a>













<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/CVPRW.2006.200" target="_blank" rel="noopener">
  DOI
</a>



  </div>
  

</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-6 year-2006">
          











  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      E.Micheli-Tzanakou</span>, <span >
      G.A.Triantafyllidis</span>, <span >
      N.Thomos</span>, <span >
      G.Nikolakis</span>, <span >
      D.Tzovaras</span>, <span class="author-highlighted">
      George Litos</span>, <span >
      M.G.Strintzis</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January, 2006
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      M-Health, Publisher: Springer US, Editors: Istepanian, Robert S. H. and Laxminarayan, Swamy and Pattichis, Constantinos S., pp.475-489
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    <a href="/publication/mobile-tele-echography/" >
      <div class="img-hover-zoom">
        <img src="/publication/mobile-tele-echography/featured_hu7c64885e93b45c1bc4ea377e54976cd3_108350_808x455_fill_q80_h2_mitchellnetravali_smart1_3.webp" height="455" width="808"
            class="article-banner" alt="User Interface Environment and Image Communication in Mobile Tele-Echography" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/mobile-tele-echography/" >User Interface Environment and Image Communication in Mobile Tele-Echography</a>
  </div>

  
  <a href="/publication/mobile-tele-echography/"  class="summary-link">
    <div class="article-style">
      <p>Mobile interconnectivity and telemedicine are important issues for achieving effectiveness in health care, since medical information can be transmitted faster and physicians can make diagnoses and treatment decisions faster. In this context, the OTELO project (OTELO, 2001) aims to develop a fully integrated end-to-end mobile tele-echography system using an ultra light, remote-controlled robot, for population groups that are not served locally by medical experts. An expert located in the expert center will do the echographic diagnosis. There will be only a “non-sonographer” person in the isolated site and the wireless transmission system will be the only link between the two sites. At the master station site, the clinical expert&rsquo;s role is to control and tele-operate the distant robot by holding a fictive probe.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.researchgate.net/publication/7948848_Mobile_Tele-Echography_User_Interface_Design/download" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/mobile-tele-echography/cite.bib">
  Cite
</a>













<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1007/0-387-26559-7_36" target="_blank" rel="noopener">
  DOI
</a>



  </div>
  

</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2005">
          











  


<div class="card-simple view-card">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      C.Canero</span>, <span >
      N.Thomos</span>, <span >
      G.A.Triantafyllidis</span>, <span class="author-highlighted">
      George Litos</span>, <span >
      M.G.Strintzis</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    March, 2005
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      IEEE Transactions on Information Technology in Biomedicine ( Volume: 9 , Issue: 1 , March 2005 )
    
  </span>
  

  

  
  
  
  

  
  

</div>

  

  
  
  
    
    <a href="/publication/tele-echography/" >
      <div class="img-hover-zoom">
        <img src="/publication/tele-echography/featured_hu046e54bbd2c055d6c9a9204113f786c5_93592_808x455_fill_q80_h2_mitchellnetravali_smart1_3.webp" height="455" width="808"
            class="article-banner" alt="Mobile Tele-echography: User Interface Design" loading="lazy">
      </div>
    </a>
  

  <div class="section-subheading article-title mb-1 mt-3">
    <a href="/publication/tele-echography/" >Mobile Tele-echography: User Interface Design</a>
  </div>

  
  <a href="/publication/tele-echography/"  class="summary-link">
    <div class="article-style">
      <p>Ultrasound imaging allows the evaluation of the degree of emergency of a patient. However, in some instances, a well-trained sonographer is unavailable to perform such echography. To cope with this issue, the Mobile Tele-Echography Using an Ultralight Robot (OTELO) project aims to develop a fully integrated end-to-end mobile tele-echography system using an ultralight remote-controlled robot for population groups that are not served locally by medical experts. This paper focuses on the user interface of the OTELO system, consisting of the following parts: an ultrasound video transmission system providing real-time images of the scanned area, an audio/video conference to communicate with the paramedical assistant and with the patient, and a virtual-reality environment, providing visual and haptic feedback to the expert, while capturing the expert&rsquo;s hand movements. These movements are reproduced by the robot at the patient site while holding the ultrasound probe against the patient skin. In addition, the user interface includes an image processing facility for enhancing the received images and the possibility to include them into a database.</p>
    </div>
  </a>
  

  
  <div class="btn-links">
    








  





<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/tele-echography/cite.bib">
  Cite
</a>













<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://doi.org/10.1109/TITB.2004.840064" target="_blank" rel="noopener">
  DOI
</a>



  </div>
  

</div>

        </div>

        
      </div>

    </div>
  </div>
</div>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  
  
  
  
  













  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by copyright-license-text">
    © 2023 by GL - This work is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank">CC BY NC ND 4.0</a>
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>





  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js"></script>




  
    <script src="https://cdn.jsdelivr.net/gh/desandro/imagesloaded@v4.1.4/imagesloaded.pkgd.min.js" integrity="sha512-S5PZ9GxJZO16tT9r3WJp/Safn31eu8uWrzglMahDT4dsmgqWonRY9grk3j+3tfuPr9WJNsfooOR7Gi7HL5W2jw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/metafizzy/isotope@v3.0.6/dist/isotope.pkgd.min.js" integrity="sha512-Zq2BOxyhvnRFXu0+WE6ojpZLOU2jdnqbrM1hmVdGzyeCa1DgM3X5Q4A/Is9xA1IkbUeDd7755dNNI/PzSf2Pew==" crossorigin="anonymous"></script>
  

  
  

  













  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  









  <script id="dsq-count-scr" src="https://georgelitos.disqus.com/count.js" async></script>




  
  
  
  
  
  
  







<script id="page-data" type="application/json">{"use_headroom":true}</script>



  <script src="/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js" type="module"></script>









  
  


<script src="/en/js/wowchemy.min.e8ee06ba8371980ffde659871dd593b0.js"></script>







  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js" type="module"></script>


















</body>
</html>
